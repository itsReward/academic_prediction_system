{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academic Status and Dropout Prediction - Feature Engineering\n",
    "\n",
    "This notebook builds on the findings from our data exploration to implement feature engineering techniques for our academic status and dropout prediction system. Feature engineering is crucial for enhancing model performance by transforming raw data into features that better represent the underlying patterns.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Configuration](#1.-Setup-and-Configuration)\n",
    "2. [Data Loading](#2.-Data-Loading)\n",
    "3. [Feature Preprocessing](#3.-Feature-Preprocessing)\n",
    "   - [Handling Missing Values](#3.1-Handling-Missing-Values)\n",
    "   - [Handling Outliers](#3.2-Handling-Outliers)\n",
    "4. [Feature Creation](#4.-Feature-Creation)\n",
    "   - [Academic Performance Indicators](#4.1-Academic-Performance-Indicators)\n",
    "   - [Engagement Metrics](#4.2-Engagement-Metrics)\n",
    "   - [Socioeconomic Indicators](#4.3-Socioeconomic-Indicators)\n",
    "   - [Economic Context Features](#4.4-Economic-Context-Features)\n",
    "5. [Feature Transformation](#5.-Feature-Transformation)\n",
    "   - [Encoding Categorical Variables](#5.1-Encoding-Categorical-Variables)\n",
    "   - [Scaling Numerical Features](#5.2-Scaling-Numerical-Features)\n",
    "6. [Feature Selection](#6.-Feature-Selection)\n",
    "   - [Statistical Methods](#6.1-Statistical-Methods)\n",
    "   - [Model-Based Selection](#6.2-Model-Based-Selection)\n",
    "7. [Data Splitting](#7.-Data-Splitting)\n",
    "8. [Feature Set Evaluation](#8.-Feature-Set-Evaluation)\n",
    "9. [Saving Processed Data](#9.-Saving-Processed-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Let's first import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Feature engineering libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Import custom utility functions if any\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# from src.features.build_features import create_academic_indicators  # Uncomment when available\n",
    "\n",
    "# Configure visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set random state for reproducibility\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Let's load the dataset and set up our feature categorization based on the data exploration findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = '../data/raw/dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1] - 1}\")  # Excluding target column\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature categories based on data exploration findings\n",
    "cat_features = [\n",
    "    'Marital status', 'Application mode', 'Course',\n",
    "    'Daytime/evening attendance', 'Previous qualification', 'Nacionality',\n",
    "    'Mother\\'s qualification', 'Father\\'s qualification', \n",
    "    'Mother\\'s occupation', 'Father\\'s occupation',\n",
    "    'Displaced', 'Educational special needs', 'Debtor',\n",
    "    'Tuition fees up to date', 'Gender', 'Scholarship holder',\n",
    "    'International'\n",
    "]\n",
    "\n",
    "num_features = [\n",
    "    'Application order', 'Age at enrollment',\n",
    "    'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)', 'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)', 'Curricular units 1st sem (without evaluations)',\n",
    "    'Curricular units 2nd sem (credited)', 'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)', 'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)', 'Curricular units 2nd sem (without evaluations)',\n",
    "    'Unemployment rate', 'Inflation rate', 'GDP'\n",
    "]\n",
    "\n",
    "target = 'Target'\n",
    "\n",
    "# Based on data exploration, identify key features that were most predictive\n",
    "# This would come from the feature importance analysis in notebook 01\n",
    "key_academic_features = [\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Curricular units 1st sem (evaluations)',\n",
    "    'Curricular units 2nd sem (evaluations)'\n",
    "]\n",
    "\n",
    "key_demographic_features = [\n",
    "    'Age at enrollment',\n",
    "    'Scholarship holder',\n",
    "    'Marital status',\n",
    "    'Debtor'\n",
    "]\n",
    "\n",
    "key_economic_features = [\n",
    "    'Unemployment rate',\n",
    "    'Inflation rate',\n",
    "    'GDP'\n",
    "]\n",
    "\n",
    "# Check target distribution again\n",
    "target_counts = df[target].value_counts()\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(target_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Preprocessing\n",
    "\n",
    "Before creating new features, let's handle any data quality issues like missing values and outliers.\n",
    "\n",
    "### 3.1 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "# Display features with missing values (if any)\n",
    "missing_features = missing_data[missing_data['Missing Values'] > 0].sort_values(by='Missing Values', ascending=False)\n",
    "print(\"Features with missing values:\")\n",
    "display(missing_features)\n",
    "\n",
    "# If there are missing values, let's handle them\n",
    "if len(missing_features) > 0:\n",
    "    # For categorical features with missing values\n",
    "    cat_missing = [col for col in cat_features if col in missing_features.index]\n",
    "    if cat_missing:\n",
    "        # Use mode imputation for categorical features\n",
    "        for col in cat_missing:\n",
    "            mode_val = df[col].mode()[0]\n",
    "            df[col] = df[col].fillna(mode_val)\n",
    "            print(f\"Filled missing values in {col} with mode: {mode_val}\")\n",
    "    \n",
    "    # For numerical features with missing values\n",
    "    num_missing = [col for col in num_features if col in missing_features.index]\n",
    "    if num_missing:\n",
    "        # Use median imputation for numerical features\n",
    "        for col in num_missing:\n",
    "            median_val = df[col].median()\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "            print(f\"Filled missing values in {col} with median: {median_val:.2f}\")\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Handling Outliers\n",
    "\n",
    "We'll use the IQR method to detect and handle outliers in numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using IQR method\n",
    "def detect_outliers_iqr(data, feature):\n",
    "    q1 = data[feature].quantile(0.25)\n",
    "    q3 = data[feature].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = data[(data[feature] < lower_bound) | (data[feature] > upper_bound)][feature]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Check for outliers in numerical features\n",
    "outlier_summary = []\n",
    "\n",
    "for feature in num_features:\n",
    "    outliers, lower_bound, upper_bound = detect_outliers_iqr(df, feature)\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_percentage = (outlier_count / len(df)) * 100\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': feature,\n",
    "        'Outlier Count': outlier_count,\n",
    "        'Outlier Percentage': outlier_percentage,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "display(outlier_df.sort_values(by='Outlier Percentage', ascending=False))\n",
    "\n",
    "# Handle outliers for features with significant outliers (e.g., > 5%)\n",
    "# We'll cap the values at the boundaries rather than removing rows\n",
    "significant_outliers = outlier_df[outlier_df['Outlier Percentage'] > 5]['Feature'].tolist()\n",
    "\n",
    "for feature in significant_outliers:\n",
    "    _, lower_bound, upper_bound = detect_outliers_iqr(df, feature)\n",
    "    print(f\"Capping outliers for {feature}\")\n",
    "    # Cap the lower and upper bounds\n",
    "    df[feature] = df[feature].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# For features with fewer outliers, we'll keep them as they might be important signals\n",
    "print(f\"\\nFeatures with significant outliers (>5%): {significant_outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Creation\n",
    "\n",
    "Based on our data exploration, we'll create new features that might help improve model performance.\n",
    "\n",
    "### 4.1 Academic Performance Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aggregated academic performance indicators\n",
    "\n",
    "# 1. Success Rate (Approved vs. Enrolled)\n",
    "df['1st_sem_success_rate'] = df['Curricular units 1st sem (approved)'] / df['Curricular units 1st sem (enrolled)'].replace(0, 1)\n",
    "df['2nd_sem_success_rate'] = df['Curricular units 2nd sem (approved)'] / df['Curricular units 2nd sem (enrolled)'].replace(0, 1)\n",
    "df['overall_success_rate'] = (df['Curricular units 1st sem (approved)'] + df['Curricular units 2nd sem (approved)']) / \\\n",
    "                           (df['Curricular units 1st sem (enrolled)'] + df['Curricular units 2nd sem (enrolled)']).replace(0, 1)\n",
    "\n",
    "# Replace infinity values with 0 (in case of division by 0)\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# 2. Evaluation Engagement Ratio\n",
    "df['1st_sem_evaluation_ratio'] = df['Curricular units 1st sem (evaluations)'] / df['Curricular units 1st sem (enrolled)'].replace(0, 1)\n",
    "df['2nd_sem_evaluation_ratio'] = df['Curricular units 2nd sem (evaluations)'] / df['Curricular units 2nd sem (enrolled)'].replace(0, 1)\n",
    "\n",
    "# 3. Performance Trend (2nd semester vs 1st semester)\n",
    "df['grade_trend'] = df['Curricular units 2nd sem (grade)'] - df['Curricular units 1st sem (grade)']\n",
    "df['approval_trend'] = df['Curricular units 2nd sem (approved)'] - df['Curricular units 1st sem (approved)']\n",
    "\n",
    "# 4. Weighted Grade (considering number of units)\n",
    "df['weighted_grade'] = (df['Curricular units 1st sem (grade)'] * df['Curricular units 1st sem (enrolled)'] + \n",
    "                       df['Curricular units 2nd sem (grade)'] * df['Curricular units 2nd sem (enrolled)']) / \\\n",
    "                      (df['Curricular units 1st sem (enrolled)'] + df['Curricular units 2nd sem (enrolled)']).replace(0, 1)\n",
    "\n",
    "# 5. Non-evaluation Rate\n",
    "df['1st_sem_non_eval_rate'] = df['Curricular units 1st sem (without evaluations)'] / df['Curricular units 1st sem (enrolled)'].replace(0, 1)\n",
    "df['2nd_sem_non_eval_rate'] = df['Curricular units 2nd sem (without evaluations)'] / df['Curricular units 2nd sem (enrolled)'].replace(0, 1)\n",
    "\n",
    "# 6. Credit Efficiency\n",
    "df['credit_efficiency'] = (df['Curricular units 1st sem (credited)'] + df['Curricular units 2nd sem (credited)']) / \\\n",
    "                         (df['Curricular units 1st sem (enrolled)'] + df['Curricular units 2nd sem (enrolled)']).replace(0, 1)\n",
    "\n",
    "# List of new academic features\n",
    "new_academic_features = [\n",
    "    '1st_sem_success_rate', '2nd_sem_success_rate', 'overall_success_rate',\n",
    "    '1st_sem_evaluation_ratio', '2nd_sem_evaluation_ratio',\n",
    "    'grade_trend', 'approval_trend', 'weighted_grade',\n",
    "    '1st_sem_non_eval_rate', '2nd_sem_non_eval_rate',\n",
    "    'credit_efficiency'\n",
    "]\n",
    "\n",
    "# Add to numerical features list\n",
    "num_features.extend(new_academic_features)\n",
    "\n",
    "# Display summary of new features\n",
    "print(\"Summary of new academic performance indicators:\")\n",
    "display(df[new_academic_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Engagement Metrics\n",
    "\n",
    "Now let's create features that reflect student engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engagement metrics\n",
    "\n",
    "# 1. Overall Engagement Score (using evaluations vs. enrolled)\n",
    "df['engagement_score'] = ((df['Curricular units 1st sem (evaluations)'] / df['Curricular units 1st sem (enrolled)'].replace(0, 1)) + \n",
    "                        (df['Curricular units 2nd sem (evaluations)'] / df['Curricular units 2nd sem (enrolled)'].replace(0, 1))) / 2 * 100\n",
    "\n",
    "# 2. Dropout Risk Indicator (based on non-evaluation rate)\n",
    "df['dropout_risk_indicator'] = (df['1st_sem_non_eval_rate'] + df['2nd_sem_non_eval_rate']) / 2 * 100\n",
    "\n",
    "# 3. Academic Consistency (standard deviation of success rates)\n",
    "df['academic_consistency'] = np.where(\n",
    "    (df['1st_sem_success_rate'] > 0) & (df['2nd_sem_success_rate'] > 0),\n",
    "    100 - (abs(df['1st_sem_success_rate'] - df['2nd_sem_success_rate']) * 50),\n",
    "    0  # If either semester has zero success rate, consistency is 0\n",
    ")\n",
    "\n",
    "# 4. Academic Momentum (improvement from 1st to 2nd semester)\n",
    "df['academic_momentum'] = np.where(\n",
    "    df['approval_trend'] > 0,\n",
    "    df['approval_trend'] * 10,  # Positive momentum\n",
    "    df['approval_trend'] * 5    # Negative momentum (less weight)\n",
    ")\n",
    "\n",
    "# List of new engagement features\n",
    "new_engagement_features = [\n",
    "    'engagement_score', 'dropout_risk_indicator',\n",
    "    'academic_consistency', 'academic_momentum'\n",
    "]\n",
    "\n",
    "# Add to numerical features list\n",
    "num_features.extend(new_engagement_features)\n",
    "\n",
    "# Display summary of new engagement features\n",
    "print(\"Summary of new engagement metrics:\")\n",
    "display(df[new_engagement_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Socioeconomic Indicators\n",
    "\n",
    "Let's create features that combine socioeconomic indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create socioeconomic indicators\n",
    "\n",
    "# 1. Family Educational Support (combining mother's and father's qualification)\n",
    "df['family_education'] = df[\"Mother's qualification\"] + df[\"Father's qualification\"]\n",
    "\n",
    "# 2. Financial Status Indicator\n",
    "df['financial_status'] = df['Scholarship holder'] * 5 + (1 - df['Debtor']) * 5 + (df['Tuition fees up to date']) * 5\n",
    "\n",
    "# 3. Social Support Index (based on scholarship, financial status, and family education)\n",
    "df['social_support_index'] = df['Scholarship holder'] * 10 + df['family_education'] / 2\n",
    "\n",
    "# 4. Financial Risk (debtor status and tuition payment)\n",
    "df['financial_risk'] = df['Debtor'] * 5 + (1 - df['Tuition fees up to date']) * 5\n",
    "\n",
    "# List of new socioeconomic features\n",
    "new_socioeconomic_features = [\n",
    "    'family_education', 'financial_status',\n",
    "    'social_support_index', 'financial_risk'\n",
    "]\n",
    "\n",
    "# Add to numerical features list\n",
    "num_features.extend(new_socioeconomic_features)\n",
    "\n",
    "# Display summary of new socioeconomic features\n",
    "print(\"Summary of new socioeconomic indicators:\")\n",
    "display(df[new_socioeconomic_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Economic Context Features\n",
    "\n",
    "Let's create features that combine economic indicators with student characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create economic context features\n",
    "\n",
    "# 1. Economic Pressure Index (combination of unemployment and inflation)\n",
    "df['economic_pressure'] = df['Unemployment rate'] + df['Inflation rate'] - df['GDP'] / 100\n",
    "\n",
    "# 2. Economic Risk for Non-Scholarship Students\n",
    "df['economic_risk_non_scholarship'] = np.where(\n",
    "    df['Scholarship holder'] == 0,\n",
    "    df['economic_pressure'] * 1.5,  # Higher risk for non-scholarship students\n",
    "    df['economic_pressure'] * 0.5   # Lower risk for scholarship students\n",
    ")\n",
    "\n",
    "# 3. Economic Support Need (based on economic indicators and financial status)\n",
    "df['economic_support_need'] = df['economic_pressure'] * (10 - df['financial_status']) / 10\n",
    "\n",
    "# List of new economic context features\n",
    "new_economic_features = [\n",
    "    'economic_pressure', 'economic_risk_non_scholarship', 'economic_support_need'\n",
    "]\n",
    "\n",
    "# Add to numerical features list\n",
    "num_features.extend(new_economic_features)\n",
    "\n",
    "# Display summary of new economic context features\n",
    "print(\"Summary of new economic context features:\")\n",
    "display(df[new_economic_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Transformation\n",
    "\n",
    "Let's transform our features to make them more suitable for machine learning models.\n",
    "\n",
    "### 5.1 Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a copy of the original DataFrame\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df_processed['Target_encoded'] = label_encoder.fit_transform(df_processed[target])\n",
    "target_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Target Encoding Mapping:\")\n",
    "for original, encoded in target_mapping.items():\n",
    "    print(f\"{original} -> {encoded}\")\n",
    "\n",
    "# One-hot encode categorical features with low cardinality (<= 10 categories)\n",
    "# For high-cardinality features, we'll use target encoding later\n",
    "cat_features_low_card = []\n",
    "cat_features_high_card = []\n",
    "\n",
    "for feature in cat_features:\n",
    "    if df_processed[feature].nunique() <= 10:\n",
    "        cat_features_low_card.append(feature)\n",
    "    else:\n",
    "        cat_features_high_card.append(feature)\n",
    "\n",
    "# One-hot encode low-cardinality features\n",
    "if cat_features_low_card:\n",
    "    print(f\"\\nOne-hot encoding {len(cat_features_low_card)} low-cardinality features\")\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "    encoded_data = encoder.fit_transform(df_processed[cat_features_low_card])\n",
    "    encoded_feature_names = [f\"{col}_{cat}\" for col, cats in zip(cat_features_low_card, encoder.categories_) \n",
    "                           for cat in cats[1:]]  # Drop the first category\n",
    "    \n",
    "    # Create a DataFrame with encoded features\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoded_feature_names, index=df_processed.index)\n",
    "    \n",
    "    # Combine with original DataFrame\n",
    "    df_processed = pd.concat([df_processed, encoded_df], axis=1)\n",
    "    \n",
    "    # Note these encoded feature names for later use\n",
    "    print(f\"Added {len(encoded_feature_names)} one-hot encoded features\")\n",
    "else:\n",
    "    encoded_feature_names = []\n",
    "    print(\"No low-cardinality categorical features to one-hot encode\")\n",
    "\n",
    "# For high-cardinality features, use target encoding (mean target encoding)\n",
    "if cat_features_high_card:\n",
    "    print(f\"\\nTarget encoding {len(cat_features_high_card)} high-cardinality features\")\n",
    "    target_encoded_feature_names = []\n",
    "    \n",
    "    for feature in cat_features_high_card:\n",
    "        # Calculate mean target value for each category\n",
    "        target_means = df_processed.groupby(feature)['Target_encoded'].mean()\n",
    "        \n",
    "        # Create new column with target encoding\n",
    "        encoded_feature_name = f\"{feature}_target_encoded\"\n",
    "        df_processed[encoded_feature_name] = df_processed[feature].map(target_means)\n",
    "        \n",
    "        # Add to list of target encoded features\n",
    "        target_encoded_feature_names.append(encoded_feature_name)\n",
    "    \n",
    "    print(f\"Added {len(target_encoded_feature_names)} target encoded features\")\n",
    "else:\n",
    "    target_encoded_feature_names = []\n",
    "    print(\"No high-cardinality categorical features to target encode\")\n",
    "\n",
    "# Update numerical features list with encoded feature names\n",
    "all_encoded_features = encoded_feature_names + target_encoded_feature_names\n",
    "num_features.extend(all_encoded_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Scaling Numerical Features\n",
    "\n",
    "Let's scale our numerical features to ensure they're on comparable scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scale the numerical features using StandardScaler\n",
    "# We'll keep the original features and add scaled versions\n",
    "\n",
    "# Choose features to scale (original numerical features, not derived ones for transparency)\n",
    "features_to_scale = [\n",
    "    'Application order', 'Age at enrollment',\n",
    "    'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)', 'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)', 'Curricular units 1st sem (without evaluations)',\n",
    "    'Curricular units 2nd sem (credited)', 'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)', 'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)', 'Curricular units 2nd sem (without evaluations)',\n",
    "    'Unemployment rate', 'Inflation rate', 'GDP'\n",
    "]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_processed[features_to_scale])\n",
    "scaled_feature_names = [f\"{col}_scaled\" for col in features_to_scale]\n",
    "\n",
    "# Create a DataFrame with scaled features\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=scaled_feature_names, index=df_processed.index)\n",
    "\n",
    "# Combine with processed DataFrame\n",
    "df_processed = pd.concat([df_processed, scaled_df], axis=1)\n",
    "\n",
    "# Add scaled feature names to numerical features list\n",
    "num_features.extend(scaled_feature_names)\n",
    "\n",
    "print(f\"Added {len(scaled_feature_names)} scaled features\")\n",
    "print(f\"Total features in df_processed: {df_processed.shape[1]}\")\n",
    "\n",
    "# Display summary of scaled features\n",
    "print(\"\\nSummary of scaled features:\")\n",
    "display(df_processed[scaled_feature_names].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection\n",
    "\n",
    "Let's select the most relevant features for our model using both statistical methods and model-based selection.\n",
    "\n",
    "### 6.1 Statistical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's collect all our numerical features for feature selection\n",
    "# Exclude the original categorical features and target\n",
    "all_features_for_selection = [col for col in df_processed.columns \n",
    "                            if col not in cat_features + [target, 'Target_encoded']]\n",
    "\n",
    "print(f\"Number of features for selection: {len(all_features_for_selection)}\")\n",
    "\n",
    "# Prepare X and y for feature selection\n",
    "X = df_processed[all_features_for_selection]\n",
    "y = df_processed['Target_encoded']\n",
    "\n",
    "# 1. ANOVA F-value for feature selection\n",
    "print(\"\\nFeature selection using ANOVA F-value:\")\n",
    "f_selector = SelectKBest(score_func=f_classif, k=20)  # Select top 20 features\n",
    "f_selector.fit(X, y)\n",
    "\n",
    "# Get scores and p-values\n",
    "f_scores = pd.DataFrame({\n",
    "    'Feature': all_features_for_selection,\n",
    "    'F_Score': f_selector.scores_,\n",
    "    'P_Value': f_selector.pvalues_\n",
    "})\n",
    "\n",
    "# Display top features by F-score\n",
    "top_f_features = f_scores.sort_values(by='F_Score', ascending=False).head(20)\n",
    "display(top_f_features)\n",
    "\n",
    "# Get selected feature names\n",
    "f_support = f_selector.get_support()\n",
    "f_selected_features = [all_features_for_selection[i] for i in range(len(all_features_for_selection)) if f_support[i]]\n",
    "print(f\"Selected {len(f_selected_features)} features using ANOVA F-value\")\n",
    "\n",
    "# 2. Mutual Information for feature selection\n",
    "print(\"\\nFeature selection using Mutual Information:\")\n",
    "mi_selector = SelectKBest(score_func=mutual_info_classif, k=20)  # Select top 20 features\n",
    "mi_selector.fit(X, y)\n",
    "\n",
    "# Get scores\n",
    "mi_scores = pd.DataFrame({\n",
    "    'Feature': all_features_for_selection,\n",
    "    'MI_Score': mi_selector.scores_\n",
    "})\n",
    "\n",
    "# Display top features by MI score\n",
    "top_mi_features = mi_scores.sort_values(by='MI_Score', ascending=False).head(20)\n",
    "display(top_mi_features)\n",
    "\n",
    "# Get selected feature names\n",
    "mi_support = mi_selector.get_support()\n",
    "mi_selected_features = [all_features_for_selection[i] for i in range(len(all_features_for_selection)) if mi_support[i]]\n",
    "print(f\"Selected {len(mi_selected_features)} features using Mutual Information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model-Based Selection\n",
    "\n",
    "Now, let's use a Random Forest model to evaluate feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest for feature importance\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    'Feature': all_features_for_selection,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "rf_importance_df = rf_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top 20 features\n",
    "print(\"Top 20 features by Random Forest importance:\")\n",
    "display(rf_importance_df.head(20))\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=rf_importance_df.head(20))\n",
    "plt.title('Top 20 Features by Random Forest Importance', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select top 20 features based on Random Forest importance\n",
    "rf_selected_features = rf_importance_df.head(20)['Feature'].tolist()\n",
    "print(f\"Selected {len(rf_selected_features)} features using Random Forest importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined set of selected features from all methods\n",
    "all_selected_features = list(set(f_selected_features + mi_selected_features + rf_selected_features))\n",
    "print(f\"Total unique features selected across all methods: {len(all_selected_features)}\")\n",
    "print(\"\\nFinal selected features:\")\n",
    "for feature in sorted(all_selected_features):\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "# Create a final feature set that includes all selected features\n",
    "final_features = all_selected_features.copy()\n",
    "\n",
    "# Add target for completeness\n",
    "final_features.append('Target')\n",
    "final_features.append('Target_encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Splitting\n",
    "\n",
    "Let's split our data into training and testing sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset with selected features\n",
    "df_final = df_processed[final_features]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = df_final.drop(columns=['Target', 'Target_encoded'])\n",
    "y = df_final['Target_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "# Verify class distribution in train and test sets\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nClass distribution in testing set:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Set Evaluation\n",
    "\n",
    "Let's evaluate our engineered feature set using a simple Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the feature set using Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for more robust evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores = cross_val_score(rf_model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-validation accuracy scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Saving Processed Data\n",
    "\n",
    "Let's save our processed data and feature information for the model training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "processed_data_dir = '../data/processed'\n",
    "if not os.path.exists(processed_data_dir):\n",
    "    os.makedirs(processed_data_dir)\n",
    "\n",
    "# Save the final processed dataframe\n",
    "df_final.to_csv(f'{processed_data_dir}/processed_data.csv', index=False)\n",
    "print(f\"Saved processed data to {processed_data_dir}/processed_data.csv\")\n",
    "\n",
    "# Save train-test split\n",
    "train_data = pd.concat([X_train, y_train.reset_index(drop=True)], axis=1)\n",
    "test_data = pd.concat([X_test, y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "train_data.to_csv(f'{processed_data_dir}/train_data.csv', index=False)\n",
    "test_data.to_csv(f'{processed_data_dir}/test_data.csv', index=False)\n",
    "\n",
    "print(f\"Saved train data to {processed_data_dir}/train_data.csv\")\n",
    "print(f\"Saved test data to {processed_data_dir}/test_data.csv\")\n",
    "\n",
    "# Save label encoder for later use\n",
    "with open(f'{processed_data_dir}/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(f\"Saved label encoder to {processed_data_dir}/label_encoder.pkl\")\n",
    "\n",
    "# Save feature information\n",
    "feature_info = {\n",
    "    'original_features': {\n",
    "        'categorical': cat_features,\n",
    "        'numerical': num_features[:len(df.columns) - len(cat_features) - 1]  # Original num features\n",
    "    },\n",
    "    'engineered_features': {\n",
    "        'academic': new_academic_features,\n",
    "        'engagement': new_engagement_features,\n",
    "        'socioeconomic': new_socioeconomic_features,\n",
    "        'economic': new_economic_features\n",
    "    },\n",
    "    'transformed_features': {\n",
    "        'encoded': all_encoded_features,\n",
    "        'scaled': scaled_feature_names\n",
    "    },\n",
    "    'selected_features': {\n",
    "        'anova': f_selected_features,\n",
    "        'mutual_info': mi_selected_features,\n",
    "        'random_forest': rf_selected_features,\n",
    "        'final': [f for f in final_features if f not in ['Target', 'Target_encoded']]\n",
    "    },\n",
    "    'target_mapping': target_mapping\n",
    "}\n",
    "\n",
    "with open(f'{processed_data_dir}/feature_info.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "print(f\"Saved feature information to {processed_data_dir}/feature_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "In this notebook, we performed comprehensive feature engineering for our academic status and dropout prediction system. Here's a summary of what we accomplished:\n",
    "\n",
    "1. **Feature Preprocessing**:\n",
    "   - Handled missing values through imputation\n",
    "   - Identified and capped outliers using the IQR method\n",
    "\n",
    "2. **Feature Creation**:\n",
    "   - Created academic performance indicators (success rates, grade trends, etc.)\n",
    "   - Developed engagement metrics to capture student participation\n",
    "   - Generated socioeconomic indicators by combining family and financial features\n",
    "   - Created economic context features relating external factors to student characteristics\n",
    "\n",
    "3. **Feature Transformation**:\n",
    "   - Encoded categorical variables using one-hot encoding and target encoding\n",
    "   - Scaled numerical features for better model performance\n",
    "\n",
    "4. **Feature Selection**:\n",
    "   - Applied statistical methods (ANOVA F-test, Mutual Information)\n",
    "   - Used model-based selection with Random Forest importance\n",
    "   - Combined methods to create a final feature set\n",
    "\n",
    "5. **Data Splitting and Evaluation**:\n",
    "   - Split data into training and testing sets\n",
    "   - Evaluated feature set performance using a Random Forest model\n",
    "   - Validated results with cross-validation\n",
    "\n",
    "6. **Data Persistence**:\n",
    "   - Saved processed data and feature information for model training\n",
    "\n",
    "**Next Steps**:\n",
    "1. Develop and evaluate multiple machine learning models in the model training notebook\n",
    "2. Perform hyperparameter tuning to optimize model performance\n",
    "3. Implement more sophisticated ensemble techniques\n",
    "4. Create a robust pipeline for production deployment\n",
    "\n",
    "The engineered features have shown promising predictive power in our initial evaluation, with clear patterns emerging in relation to the target variable. Our next step is to build and optimize machine learning models using these features to create an accurate academic status and dropout prediction system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}